{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ae44e39-92ca-48f3-8cbf-a1be37bb9ec7",
   "metadata": {},
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8faaffdf-e98d-41eb-9b02-0b0039a6f8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FIRST 5 ROWS ---\n",
      "  student_id cohort  attended_sessions  expected_sessions\n",
      "0       S001   beta                  6                  6\n",
      "1       S002  gamma                  2                  6\n",
      "2       S003  gamma                  1                  6\n",
      "3       S004  alpha                  1                  6\n",
      "4       S005  gamma                  6                  6\n",
      "\n",
      "--- DATAFRAME INFO ---\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype\n",
      "---  ------             --------------  -----\n",
      " 0   student_id         24 non-null     str  \n",
      " 1   cohort             24 non-null     str  \n",
      " 2   attended_sessions  24 non-null     int64\n",
      " 3   expected_sessions  24 non-null     int64\n",
      "dtypes: int64(2), str(2)\n",
      "memory usage: 900.0 bytes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# 1. Creating the raw data\n",
    "# We use range(1, 25) to get numbers 1 through 24\n",
    "attendance_raw = [\n",
    "    {\n",
    "        \"student_id\": f\"S{i:03}\",\n",
    "        \"cohort\": random.choice([\"alpha\", \"beta\", \"gamma\"]),\n",
    "        \"attended_sessions\": random.randint(0, 6),\n",
    "        \"expected_sessions\": 6\n",
    "    } \n",
    "    for i in range(1, 25)\n",
    "]\n",
    "\n",
    "# 2. Loading into a pandas DataFrame\n",
    "# The pd.DataFrame() constructor can take a list of dictionaries automatically.\n",
    "attendance = pd.DataFrame(attendance_raw)\n",
    "\n",
    "# 3. Inspection\n",
    "# .head(n) returns the first n rows.\n",
    "# .info() gives the technical summary (index, dtypes, non-null counts, memory).\n",
    "print(\"--- FIRST 5 ROWS ---\")\n",
    "print(attendance.head())\n",
    "\n",
    "print(\"\\n--- DATAFRAME INFO ---\")\n",
    "attendance.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a47ef46-321a-4361-9b55-3838743ca27b",
   "metadata": {},
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25dfe22f-d97d-45c2-a4d3-2333d43a3276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ALIGNMENT CHECK (First 12 rows) ---\n",
      "            attended_sessions  adjusted_attendance\n",
      "student_id                                        \n",
      "S001                        6                  7.0\n",
      "S002                        2                  2.0\n",
      "S003                        1                  3.0\n",
      "S004                        1                  2.0\n",
      "S005                        6                  6.0\n",
      "S006                        6                  7.0\n",
      "S007                        1                  1.0\n",
      "S008                        6                  9.0\n",
      "S009                        2                  3.0\n",
      "S010                        2                  2.0\n",
      "S011                        1                  NaN\n",
      "S012                        5                  NaN\n",
      "\n",
      "--- UPDATED ADJUSTED ATTENDANCE (NaNs Filled) ---\n",
      "            attended_sessions  adjusted_attendance\n",
      "student_id                                        \n",
      "S001                        6                  7.0\n",
      "S002                        2                  2.0\n",
      "S003                        1                  3.0\n",
      "S004                        1                  2.0\n",
      "S005                        6                  6.0\n",
      "S006                        6                  7.0\n",
      "S007                        1                  1.0\n",
      "S008                        6                  9.0\n",
      "S009                        2                  3.0\n",
      "S010                        2                  2.0\n",
      "S011                        1                  1.0\n",
      "S012                        5                  5.0\n"
     ]
    }
   ],
   "source": [
    "# 1. Setting the Index\n",
    "# .set_index() moves a column to the 'Label' position on the left.\n",
    "# we use drop=True (default) to remove the original column.\n",
    "attendance_indexed = attendance.set_index(\"student_id\")\n",
    "\n",
    "# 2. Creating the 'Excused Absences' Series\n",
    "# We include IDs from S001-S010, and some 'fake' IDs (S099) to test alignment.\n",
    "excused_data = {\n",
    "    \"S001\": 1, \"S002\": 0, \"S003\": 2, \"S004\": 1, \"S005\": 0,\n",
    "    \"S006\": 1, \"S007\": 0, \"S008\": 3, \"S009\": 1, \"S010\": 0,\n",
    "    \"S999\": 5, \"S888\": 2 # These IDs do NOT exist in our original DataFrame\n",
    "}\n",
    "excused_absences = pd.Series(excused_data, name=\"excused\")\n",
    "\n",
    "# 3. Creating the 'adjusted_attendance' column\n",
    "# This is where ALIGNMENT happens. Pandas looks for matching Student IDs.\n",
    "attendance_indexed[\"adjusted_attendance\"] = (\n",
    "    attendance_indexed[\"attended_sessions\"] + excused_absences\n",
    ")\n",
    "\n",
    "# 4. Validation: Showing the result of alignment\n",
    "print(\"--- ALIGNMENT CHECK (First 12 rows) ---\")\n",
    "print(attendance_indexed[[\"attended_sessions\", \"adjusted_attendance\"]].head(12))\n",
    "\n",
    "# 5. Filling Missing Values\n",
    "# We use .fillna() to replace NaNs. We pass the original column so that \n",
    "# if there were no excused absences, the adjusted attendance equals the original.\n",
    "attendance_indexed[\"adjusted_attendance\"] = (\n",
    "    attendance_indexed[\"adjusted_attendance\"].fillna(attendance_indexed[\"attended_sessions\"])\n",
    ")\n",
    "\n",
    "print(\"\\n--- UPDATED ADJUSTED ATTENDANCE (NaNs Filled) ---\")\n",
    "print(attendance_indexed[[\"attended_sessions\", \"adjusted_attendance\"]].head(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cf3f2b-7ecd-42a6-a723-a19685d3d4db",
   "metadata": {},
   "source": [
    "Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37eda99a-5a70-456f-8220-4c41065830d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BEFORE CLEANING (Unique Values) ---\n",
      "<StringArray>\n",
      "['  alpha  ', 'BETA', 'gaMma ', 'alpha', 'gamma', 'beta']\n",
      "Length: 6, dtype: str\n",
      "\n",
      "--- AFTER CLEANING (Unique Values) ---\n",
      "<StringArray>\n",
      "['alpha', 'beta', 'gamma']\n",
      "Length: 3, dtype: str\n"
     ]
    }
   ],
   "source": [
    "# 1. Intentionally \"messing up\" some data\n",
    "# We use .iloc (position-based) to target specific cells\n",
    "attendance_indexed.iloc[0, 0] = \"  alpha  \"  # Row 0, Column 0 (cohort)\n",
    "attendance_indexed.iloc[1, 0] = \"BETA\"       # Row 1, Column 0\n",
    "attendance_indexed.iloc[2, 0] = \"gaMma \"     # Row 2, Column 0\n",
    "\n",
    "print(\"--- BEFORE CLEANING (Unique Values) ---\")\n",
    "# .unique() shows every distinct value in the column\n",
    "print(attendance_indexed[\"cohort\"].unique())\n",
    "\n",
    "# 2. Cleaning the data using vectorized operations\n",
    "# We chain the methods: first strip, then lowercase\n",
    "attendance_indexed[\"cohort\"] = (\n",
    "    attendance_indexed[\"cohort\"]\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "# 3. Validation\n",
    "print(\"\\n--- AFTER CLEANING (Unique Values) ---\")\n",
    "cleaned_uniques = attendance_indexed[\"cohort\"].unique()\n",
    "print(cleaned_uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb690961-f3d6-4368-9788-2183672c8c15",
   "metadata": {},
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bd67a70-8cee-4db3-8a88-d7c94a3711a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LOW ATTENDANCE STUDENTS (Count: 18) ---\n",
      "           cohort  attended_sessions  expected_sessions  adjusted_attendance\n",
      "student_id                                                                  \n",
      "S002         beta                  2                  6                  2.0\n",
      "S003        gamma                  1                  6                  3.0\n",
      "S004        alpha                  1                  6                  2.0\n",
      "S007         beta                  1                  6                  1.0\n",
      "S009        alpha                  2                  6                  3.0\n",
      "\n",
      "--- AVERAGE SESSIONS BY COHORT ---\n",
      "cohort\n",
      "alpha    3.555556\n",
      "beta     3.285714\n",
      "gamma    3.625000\n",
      "Name: attended_sessions, dtype: float64\n",
      "\n",
      "Summary matches cleaned cohorts: True\n"
     ]
    }
   ],
   "source": [
    "# 1. Filter: Students with less attendance than expected\n",
    "# This creates a new DataFrame containing only the \"at-risk\" students\n",
    "low_attendance = attendance_indexed[\n",
    "    attendance_indexed[\"attended_sessions\"] < attendance_indexed[\"expected_sessions\"]\n",
    "].copy() # We use .copy() to avoid 'SettingWithCopy' warnings later\n",
    "\n",
    "print(f\"--- LOW ATTENDANCE STUDENTS (Count: {len(low_attendance)}) ---\")\n",
    "print(low_attendance.head())\n",
    "\n",
    "# 2. Summary: Average attended sessions by cohort\n",
    "# We select 'cohort' to group by, then select 'attended_sessions' to calculate.\n",
    "cohort_summary = attendance_indexed.groupby(\"cohort\")[\"attended_sessions\"].mean()\n",
    "\n",
    "print(\"\\n--- AVERAGE SESSIONS BY COHORT ---\")\n",
    "print(cohort_summary)\n",
    "\n",
    "# 3. Verification\n",
    "# Ensuring the index of our summary matches our cleaned unique values\n",
    "print(f\"\\nSummary matches cleaned cohorts: {set(cohort_summary.index) == set(cleaned_uniques)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c0c013-137f-4435-9867-64ef1a046131",
   "metadata": {},
   "source": [
    "Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2b7b0e-2522-437d-a759-99982378b007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- VALIDATION RESULTS ---\n",
      "Is every low-attendance student marked 'attendance_ok = False'? True\n",
      "\n",
      "--- FINAL DATAFRAME PREVIEW ---\n",
      "           cohort  attended_sessions  expected_sessions  adjusted_attendance  \\\n",
      "student_id                                                                     \n",
      "S001        alpha                  6                  6                  7.0   \n",
      "S002         beta                  2                  6                  2.0   \n",
      "S003        gamma                  1                  6                  3.0   \n",
      "S004        alpha                  1                  6                  2.0   \n",
      "S005        gamma                  6                  6                  6.0   \n",
      "\n",
      "            attendance_ok  \n",
      "student_id                 \n",
      "S001                 True  \n",
      "S002                False  \n",
      "S003                False  \n",
      "S004                False  \n",
      "S005                 True  \n"
     ]
    }
   ],
   "source": [
    "# 1. Creating the derived column 'attendance_ok'\n",
    "# Logic: True if attended >= expected, else False\n",
    "attendance_indexed[\"attendance_ok\"] = (\n",
    "    attendance_indexed[\"attended_sessions\"] >= attendance_indexed[\"expected_sessions\"]\n",
    ")\n",
    "\n",
    "# 2. Updating the 'low_attendance' slice\n",
    "# Since we added a column to the main DataFrame, we need to ensure our \n",
    "# low_attendance subset is aware of this new information for validation.\n",
    "# We re-run the filter to include the new column.\n",
    "low_attendance_validation = attendance_indexed[attendance_indexed[\"attended_sessions\"] < 6]\n",
    "\n",
    "# 3. Validation Check\n",
    "# We want to confirm that for all rows in low_attendance, attendance_ok is False.\n",
    "# .all() returns True only if every single value in the series is True.\n",
    "validation_check = (low_attendance_validation[\"attendance_ok\"] == False).all()\n",
    "\n",
    "print(f\"--- VALIDATION RESULTS ---\")\n",
    "print(f\"Is every low-attendance student marked 'attendance_ok = False'? {validation_check}\")\n",
    "\n",
    "# 4. Final inspection of the main DataFrame\n",
    "print(\"\\n--- FINAL DATAFRAME PREVIEW ---\")\n",
    "print(attendance_indexed.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
